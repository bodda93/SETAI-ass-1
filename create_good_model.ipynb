{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c71e843",
   "metadata": {},
   "source": [
    "# create_good_model.ipynb — Purposefully **Good** Model (Fairness-Aware Feature Use)\n",
    "\n",
    "This notebook trains a model that is “good” in the assignment’s sense:\n",
    "- It aims to **reduce undesirable biased patterns** by excluding sensitive/proxy/leakage features.\n",
    "- It still reports classical ML metrics.\n",
    "\n",
    "**Critical interface requirement**:\n",
    "The independent tester will provide inputs with the original full feature set.\n",
    "So we train/export a **pipeline** that:\n",
    "1) accepts **all original features**,\n",
    "2) internally drops the disallowed columns,\n",
    "3) runs the classifier on the remaining columns.\n",
    "\n",
    "It then:\n",
    "- Exports the model to ONNX,\n",
    "- Randomly assigns it to `model_1.onnx` or `model_2.onnx` using shared `model_assignment.json`,\n",
    "- Reports performance:\n",
    "  1) classical metrics (Accuracy, ROC-AUC, PR-AUC)\n",
    "  2) part-2 tests (gender partition + gender-flip metamorphic), executed via ONNX runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-05T20:58:50.827864300Z",
     "start_time": "2026-01-05T20:58:50.776493Z"
    }
   },
   "id": "da63c657799bec3f"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data/investigation_train_large_checked.csv shape: (130000, 318)\n",
      "Features: 315 Positive rate: 0.15\n"
     ]
    }
   ],
   "source": [
    "import os, json, random, shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, average_precision_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "rstate = 1\n",
    "target = \"checked\"\n",
    "\n",
    "\n",
    "\n",
    "data_path = \"data/investigation_train_large_checked.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "print(\"Loaded:\", data_path, \"shape:\", df.shape)\n",
    "\n",
    "y = df[target].astype(int).values\n",
    "\n",
    "drop_cols = [target, \"Ja\", \"Nee\"]\n",
    "\n",
    "X = df.drop(columns=drop_cols)\n",
    "\n",
    "print(\"Features:\", X.shape[1], \"Positive rate:\", y.mean().round(4))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2026-01-05T20:58:53.479914800Z",
     "start_time": "2026-01-05T20:58:50.780033500Z"
    }
   },
   "id": "146765c12a014b01"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1192c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:58:53.855387900Z",
     "start_time": "2026-01-05T20:58:53.472800900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((104000, 315), (26000, 315))"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=rstate, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd07b1d",
   "metadata": {},
   "source": [
    "## Model choice (Good model)\n",
    "\n",
    "We use **Logistic Regression** because:\n",
    "- It is a strong, stable baseline and easier to justify in policy-sensitive contexts.\n",
    "- With a fairness-aware feature set, it reduces the risk of exploiting complex proxy interactions.\n",
    "- It converts cleanly to ONNX.\n",
    "\n",
    "The “goodness” comes primarily from the **feature policy** below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5beab1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T20:58:53.861028700Z",
     "start_time": "2026-01-05T20:58:53.849517600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping: 25\n",
      "Keeping : 290\n"
     ]
    },
    {
     "data": {
      "text/plain": "['adres_recentste_buurt_groot_ijsselmonde',\n 'adres_recentste_buurt_nieuwe_westen',\n 'adres_recentste_buurt_other',\n 'adres_recentste_buurt_oude_noorden',\n 'adres_recentste_buurt_vreewijk',\n 'adres_recentste_wijk_charlois',\n 'adres_recentste_wijk_delfshaven',\n 'adres_recentste_wijk_feijenoord',\n 'adres_recentste_wijk_ijsselmonde',\n 'adres_recentste_wijk_kralingen_c',\n 'adres_recentste_wijk_noord',\n 'adres_recentste_wijk_other',\n 'adres_recentste_wijk_prins_alexa',\n 'adres_recentste_wijk_stadscentru',\n 'belemmering_hist_taal',\n 'contacten_onderwerp_beoordelen_taaleis',\n 'contacten_onderwerp_boolean_beoordelen_taaleis',\n 'contacten_onderwerp_boolean_taaleis___voldoet',\n 'persoon_geslacht_vrouw',\n 'persoonlijke_eigenschappen_spreektaal']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the set of columns to drop (fairness-aware policy)\n",
    "cols = list(X_train.columns)\n",
    "drop = set()\n",
    "\n",
    "\n",
    "# Gender ofc\n",
    "if \"persoon_geslacht_vrouw\" in cols:\n",
    "    drop.add(\"persoon_geslacht_vrouw\")\n",
    "\n",
    "# Language / indirect ethnicity\n",
    "for col in cols:\n",
    "    if col.startswith(\"persoonlijke_eigenschappen_spreektaal\"):\n",
    "        drop.add(col)\n",
    "    if col.startswith(\"persoonlijke_eigenschappen_taaleis\"):\n",
    "        drop.add(col)\n",
    "    if \"inburger\" in col or \"inburgering\" in col:\n",
    "        drop.add(col)\n",
    "    if col == \"belemmering_hist_taal\":\n",
    "        drop.add(col)\n",
    "    if col.startswith(\"contacten_onderwerp_\") and (\"taal\" in col or \"taaleis\" in col):\n",
    "        drop.add(col)\n",
    "\n",
    "# spatial profiling variables\n",
    "for col in cols:\n",
    "    if col.startswith(\"adres_recentste_wijk_\") or col.startswith(\"adres_recentste_buurt_\"):\n",
    "        drop.add(col)\n",
    "\n",
    "drop = sorted(drop)\n",
    "keep_cols = [col for col in cols if col not in drop]\n",
    "\n",
    "print(\"Dropping:\", len(drop))\n",
    "print(\"Keeping :\", len(keep_cols))\n",
    "drop[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e057be8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:06:42.308603Z",
     "start_time": "2026-01-05T20:58:53.869655700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best params: {'clf__C': 1.0, 'clf__class_weight': None}\n",
      "Best CV ROC-AUC: 0.8577820792773186\n",
      "GOOD model — Accuracy: 0.8769\n",
      "GOOD model — ROC-AUC:  0.8377\n",
      "GOOD model — PR-AUC:   0.5743\n"
     ]
    }
   ],
   "source": [
    "# Pipeline that keeps full interface but drops internally (ONNX-friendly)\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ColumnTransformer works with column indices; derive indices of keep_cols in the original column order\n",
    "col_index = {c: i for i, c in enumerate(X_train.columns)}\n",
    "keep_idx = [col_index[c] for c in keep_cols]\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[(\"keep\", \"passthrough\", keep_idx)],\n",
    "    remainder=\"drop\",\n",
    "    verbose_feature_names_out=False,\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(max_iter=2000, n_jobs=-1)\n",
    "\n",
    "good_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess),\n",
    "    (\"clf\", clf),\n",
    "])\n",
    "\n",
    "\n",
    "# Light tuning grid (kept small so it runs quickly)\n",
    "param_grid = {\n",
    "    \"clf__C\": [0.5, 1.0, 2],\n",
    "    \"clf__class_weight\": [None],\n",
    "}\n",
    "\n",
    "search = GridSearchCV(\n",
    "    estimator=good_pipe,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "good_model = search.best_estimator_\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"Best CV ROC-AUC:\", search.best_score_)\n",
    "\n",
    "p = good_model.predict_proba(X_test)[:, 1]\n",
    "yhat = (p >= 0.5).astype(int)\n",
    "\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "roc = roc_auc_score(y_test, p)\n",
    "prauc = average_precision_score(y_test, p)\n",
    "\n",
    "print(f\"GOOD model — Accuracy: {acc:.4f}\")\n",
    "print(f\"GOOD model — ROC-AUC:  {roc:.4f}\")\n",
    "print(f\"GOOD model — PR-AUC:   {prauc:.4f}\")\n",
    "\n",
    "#GOOD model — Accuracy: 0.8628\n",
    "# GOOD model — ROC-AUC:  0.8069\n",
    "# GOOD model — PR-AUC:   0.4646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76fa5fc5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:06:42.379901400Z",
     "start_time": "2026-01-05T21:06:42.308603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved temporary ONNX: model/good_model_tmp.onnx\n"
     ]
    }
   ],
   "source": [
    "# Export to ONNX should have the whole pipeline aswell\n",
    "onnx_tmp = \"model/good_model_tmp.onnx\"\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "\n",
    "initial_type = [(\"float_input\", FloatTensorType([None, X_train.shape[1]]))]\n",
    "onnx_model = convert_sklearn(good_model, initial_types=initial_type)\n",
    "\n",
    "with open(onnx_tmp, \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())\n",
    "\n",
    "print(\"Saved temporary ONNX:\", onnx_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "121b1824",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:06:42.379901400Z",
     "start_time": "2026-01-05T21:06:42.374696400Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "595c454b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:06:42.379901400Z",
     "start_time": "2026-01-05T21:06:42.379378900Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc1b0f98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T21:06:42.390125300Z",
     "start_time": "2026-01-05T21:06:42.385931100Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
